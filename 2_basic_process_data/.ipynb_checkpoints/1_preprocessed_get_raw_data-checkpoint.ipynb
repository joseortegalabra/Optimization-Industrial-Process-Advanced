{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a95f5235",
   "metadata": {},
   "source": [
    "# Cleaning data datalake - preprocessed - get raw data\n",
    "En el datalake se obtiene la data con varios errores - se procede a correguirlos\n",
    "\n",
    "Transformations:\n",
    "- Set seconds to zero\n",
    "- Aprox/round minutes to multiples of 5 minutes\n",
    "- Drop hidden duplicates\n",
    "- Inputer NaNs\n",
    "\n",
    "--------\n",
    "**DATA**:\n",
    "- INPUT: \"data_raw_bigquery.pkl\"\n",
    "- OUTPUT: \"data_raw_preprocessed.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a1078-c422-4830-b8a7-ce2f140065f2",
   "metadata": {},
   "source": [
    "## Root folder and read env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ce007d-b5e3-4f7d-9896-cd09507a0d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root path:  D:\\github-mi-repo\\Optimization-Industrial-Process\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# fix root path to save outputs\n",
    "actual_path = os.path.abspath(os.getcwd())\n",
    "list_root_path = actual_path.split('\\\\')[:-1]\n",
    "root_path = '\\\\'.join(list_root_path)\n",
    "os.chdir(root_path)\n",
    "print('root path: ', root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd12d65c-0c7d-4093-b60a-433deb529daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv # package used in jupyter notebook to read the variables in file .env\n",
    "\n",
    "\"\"\" get env variable from .env \"\"\"\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\"\"\" Read env variables and save it as python variable \"\"\"\n",
    "PROJECT_GCP = os.environ.get(\"PROJECT_GCP\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef914a3-1f2c-44e4-8e6b-b5f8290af984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c83ab771-9bc4-4c72-8a79-409652d9a771",
   "metadata": {},
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe6d1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import gcsfs\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea426212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee46fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195694f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ed951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f42d914",
   "metadata": {},
   "source": [
    "### 0. Read Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996e7bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>PV</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240FI020A_HRS_EOP.C</td>\n",
       "      <td>46.999200</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240FI020A_HRS_DO.C</td>\n",
       "      <td>11.483770</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230AIT446.PNT</td>\n",
       "      <td>11.556540</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240FIC440.MEAS</td>\n",
       "      <td>0.023512</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240FIC236.MEAS</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tag         PV   datetime\n",
       "0  240FI020A_HRS_EOP.C  46.999200 2021-01-01\n",
       "1   240FI020A_HRS_DO.C  11.483770 2021-01-01\n",
       "2        230AIT446.PNT  11.556540 2021-01-01\n",
       "3       240FIC440.MEAS   0.023512 2021-01-01\n",
       "4       240FIC236.MEAS   0.000117 2021-01-01"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_datalake = 'artifacts/data/data_raw_bigquery.pkl'\n",
    "data_datalake = pd.read_pickle(path_data_datalake)\n",
    "data_datalake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c625f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dadad987",
   "metadata": {},
   "source": [
    "### 1. Set seconds to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c482ebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "applying set_seconds_zero...\n",
      "Tamaño data raw:  (13352529, 3)\n"
     ]
    }
   ],
   "source": [
    "class set_seconds_zero(BaseEstimator,TransformerMixin):\n",
    "    '''\n",
    "    Fijar los segundos a cero.\n",
    "    Todos los datos extraidos desde el datalake fallan en los segundos y no son extraidos exactamente en el segundo 00\n",
    "    \n",
    "    Example DataFrame\n",
    "    1 S240ALDP022\t90.600000\t2022-03-20 23:55:03\n",
    "    2 S240ALDP031\t2.300000\t2022-03-20 23:55:03\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(set_seconds_zero,self).__init__()\n",
    "\n",
    "    def fit(self,DataFrame):\n",
    "        return self\n",
    "\n",
    "    def transform(self,DataFrame):\n",
    "        print('\\napplying set_seconds_zero...')\n",
    "        print('Tamaño data raw: ', DataFrame.shape)\n",
    "        \n",
    "        \n",
    "        # apply transformation\n",
    "        DataFrame['datetime'] = DataFrame['datetime'].dt.strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "        DataFrame['datetime'] = DataFrame['datetime'].astype('datetime64[ns]')\n",
    "        return DataFrame\n",
    "\n",
    "    \n",
    "# instancia de la clase\n",
    "seter_seconds = set_seconds_zero()\n",
    "\n",
    "# transformar\n",
    "basic_preprocessed_data = seter_seconds.transform(data_datalake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26532184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>PV</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240FI020A_HRS_EOP.C</td>\n",
       "      <td>46.999200</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240FI020A_HRS_DO.C</td>\n",
       "      <td>11.483770</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230AIT446.PNT</td>\n",
       "      <td>11.556540</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240FIC440.MEAS</td>\n",
       "      <td>0.023512</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240FIC236.MEAS</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tag         PV   datetime\n",
       "0  240FI020A_HRS_EOP.C  46.999200 2021-01-01\n",
       "1   240FI020A_HRS_DO.C  11.483770 2021-01-01\n",
       "2        230AIT446.PNT  11.556540 2021-01-01\n",
       "3       240FIC440.MEAS   0.023512 2021-01-01\n",
       "4       240FIC236.MEAS   0.000117 2021-01-01"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print\n",
    "basic_preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9714c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cc65c50",
   "metadata": {},
   "source": [
    "### 2. Aprox/round minutes to multiple of 5\n",
    "The data is getting each 5 minutes, but some times it is not exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa243bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "applying aprox_minutes_multiple_5...\n",
      "Minutos que aparecen en el dataframe:  [ 0  4  5  9 10 14 15 19 20 24 25 29 30 34 35 39 40 44 45 49 50 54 55 59\n",
      " 31 36 41 46 51 56  1  6 11 16 21 26  2  7 12 17 22 27 32 33 37 38 42 43\n",
      " 47 48 52 53 57 58  3  8 13 18 23 28]\n"
     ]
    }
   ],
   "source": [
    "class aprox_minutes_multiple_5(BaseEstimator,TransformerMixin):\n",
    "    '''\n",
    "    Aproximar los minutos a múltiplos de 5.\n",
    "    \n",
    "    Ejemplo:\n",
    "    - A veces no se extrae justo cada 5 minutos, o se extrae de nuevo datos, ejemplo extraer datos en minuto 5, 12, 15, 18, 20\n",
    "    - Luego hay que aproximar para que en los datos se vean como múltiplos de 5 minutos, por lo que se obtiene: 5, 10, 15, 15, 20\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(aprox_minutes_multiple_5,self).__init__()\n",
    "\n",
    "    def fit(self,DataFrame):\n",
    "        return self\n",
    "\n",
    "    def transform(self,DataFrame):\n",
    "        print('\\napplying aprox_minutes_multiple_5...')\n",
    "        print('Minutos que aparecen en el dataframe: ', DataFrame['datetime'].dt.minute.unique())\n",
    "        \n",
    "        \n",
    "        # apply transformation\n",
    "        DataFrame['datetime'] = DataFrame['datetime'].apply(lambda x: x.floor('5 min'))\n",
    "        return DataFrame\n",
    "    \n",
    "\n",
    "# instancia\n",
    "aprox_er = aprox_minutes_multiple_5()\n",
    "\n",
    "# transformar\n",
    "basic_preprocessed_data = aprox_er.transform(basic_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ad8648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>PV</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240FI020A_HRS_EOP.C</td>\n",
       "      <td>46.99920</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240FI020A_HRS_DO.C</td>\n",
       "      <td>11.48377</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230AIT446.PNT</td>\n",
       "      <td>11.55654</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tag        PV   datetime\n",
       "0  240FI020A_HRS_EOP.C  46.99920 2021-01-01\n",
       "1   240FI020A_HRS_DO.C  11.48377 2021-01-01\n",
       "2        230AIT446.PNT  11.55654 2021-01-01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print\n",
    "basic_preprocessed_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80473e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d48a4318",
   "metadata": {},
   "source": [
    "### 3. Eliminate duplicates that are generated with the same datetime (product of the approximation of the previous stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b037ffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "applying drop_duplicates_time...\n",
      "Tamaño data:  (13352529, 3)\n",
      "Tamaño data luego de borrar duplicados time:  (12543679, 3)\n",
      "Num Obs ideal: Cantidad de datos que deberían haber si se subieran todos los datos de todos los días(cantidad días * 288):  210528\n",
      "Num Obs Real: Cantidad de obs realmente existen en los datos:  208865\n",
      "Cantidad de observaciones COMPLETAS no subidas al datalake:  1663\n",
      "% observaciones COMPLETAS no subidas al datalake:  0.7899186806505587\n"
     ]
    }
   ],
   "source": [
    "class drop_duplicates_time(BaseEstimator,TransformerMixin):\n",
    "    '''\n",
    "    Eliminar los duplicados que se podrian generar en el paso anterior redondeo de minutos:\n",
    "    - dos o más observaciones del mismo tag tiene el MISMO valor y el mismo datetime\n",
    "    - dos o más observaciones del mismo tag tiene DISTINTO valor y el mismo datetime\n",
    "    \n",
    "    Ex.\n",
    "    TAG            VALUE    TIME\n",
    "    240FI020A.PNT  3363.118 2021-09-01 00:00:00\n",
    "    240FI020A.PNT  3362.869 2021-09-01 00:00:00\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(drop_duplicates_time,self).__init__()\n",
    "    \n",
    "    def fit(self,DataFrame):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,DataFrame):\n",
    "        print('\\napplying drop_duplicates_time...')\n",
    "        print('Tamaño data: ', DataFrame.shape)\n",
    "        \n",
    "        \n",
    "        # Drop duplicates. Same datetime, same tag, different value. Conservar el menor valor\n",
    "        DataFrame=DataFrame.groupby(['datetime','Tag'],as_index=False).agg({'PV':['min']})\n",
    "        DataFrame.columns=[x[0] if x[1]=='' else '_'.join(x) for x in DataFrame.columns]\n",
    "        DataFrame=DataFrame.rename(columns={'PV_min': \"PV\"})\n",
    "        print('Tamaño data luego de borrar duplicados time: ', DataFrame.shape)\n",
    "        \n",
    "        \n",
    "        \"\"\" print de info de interés. Cantidad de datos que contiene la data raw correguido el datetime vs la cantidad de datos que debería de tener \"\"\"\n",
    "        # get idel number of observations\n",
    "        days_to_query = (DataFrame.iloc[-1]['datetime'] - DataFrame.iloc[0]['datetime'])\n",
    "        ideal_number_observations = (days_to_query.days + 1) * 288\n",
    "\n",
    "        # get the real number of observations\n",
    "        real_number_observations = DataFrame['datetime'].unique().shape[0]\n",
    "        \n",
    "        # calculate the % off loss data\n",
    "        print('Num Obs ideal: Cantidad de datos que deberían haber si se subieran todos los datos de todos los días(cantidad días * 288): ', ideal_number_observations)\n",
    "        print('Num Obs Real: Cantidad de obs realmente existen en los datos: ', real_number_observations)\n",
    "        print('Cantidad de observaciones COMPLETAS no subidas al datalake: ', ideal_number_observations - real_number_observations)\n",
    "        print('% observaciones COMPLETAS no subidas al datalake: ', 100 * (1 - (real_number_observations / ideal_number_observations)))\n",
    "        \n",
    "        return DataFrame\n",
    "    \n",
    "\n",
    "# instancia de la clase\n",
    "droper_time = drop_duplicates_time()\n",
    "\n",
    "# transformar\n",
    "basic_preprocessed_data = droper_time.transform(basic_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd3dd588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Tag</th>\n",
       "      <th>PV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>230AIT446.PNT</td>\n",
       "      <td>11.556540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>240AIC022.MEAS</td>\n",
       "      <td>3.008503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>240AIC126.MEAS</td>\n",
       "      <td>11.404640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime             Tag         PV\n",
       "0 2021-01-01   230AIT446.PNT  11.556540\n",
       "1 2021-01-01  240AIC022.MEAS   3.008503\n",
       "2 2021-01-01  240AIC126.MEAS  11.404640"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print\n",
    "basic_preprocessed_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa05b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51c165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f50194a8",
   "metadata": {},
   "source": [
    "### 4. Inputer NaNs\n",
    "- Se asume que la cantidad de datos que no existen en el datalake fue por algún error en PI que lo clasificó como bad input, algún problema en la subida a BigQuery y no subió el dato\n",
    "- La planta está siempre funcionando por lo que siempre tienen que haber datos\n",
    "- Cuando hay PGP igual se guardan datos, lab se mantiene el último valor por ejemplo hasta que lo vuelven a actualizar\n",
    "- Entonces, no habría razón para que la cantidad que datos en el datalake sea distinta al valor ideal\n",
    "- Luego, estos valores faltantes se rellenan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eec419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputerNaNs(BaseEstimator,TransformerMixin):\n",
    "    '''\n",
    "    Imputer NaN since data Raw (columns)\n",
    "    Imputer NaN of each tags.\n",
    "    Output: Data Raw with each tag have the same number of observations\n",
    "    '''\n",
    "    def __init__(self, method, start_date, end_date):\n",
    "        super(ImputerNaNs,self).__init__()\n",
    "        self.method = method\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "    \n",
    "    def fit(self,DataFrame):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, DataFrame):\n",
    "        print('\\napplying ImputerNaNs...')\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame(columns=['datetime', 'Tag', 'PV'])\n",
    "\n",
    "        for tag_name in DataFrame['Tag'].unique().tolist():\n",
    "\n",
    "            # create ALL indexes each 5 minutes since begin of data until end of data. \"Indexes Full\"\n",
    "            raw= DataFrame[DataFrame['Tag']==tag_name]\n",
    "            inicio =  self.start_date         \n",
    "            fin =  self.end_date           \n",
    "            idx = pd.date_range(dt.datetime.strptime(inicio, '%Y-%m-%d'), \n",
    "                                dt.datetime.strptime(fin, '%Y-%m-%d') + dt.timedelta(days = 1), # la query incluye el ultimo dia dentro de los datos que consulta\n",
    "                                freq='5min'\n",
    "                               )\n",
    "            \n",
    "            # set into data raw the \"Indexes Full\"\n",
    "            raw=raw.set_index('datetime')\n",
    "            raw=raw.reindex(idx)  \n",
    "            raw = raw.reset_index()\n",
    "            raw=raw.rename(columns={'index':'datetime'})\n",
    "\n",
    "            #info: opcional para detener más detalles\n",
    "            print('\\nProcessing tag: ', tag_name)\n",
    "            print('Amount of null values that will be filled: ', raw['Tag'].isnull().sum())\n",
    "            print('Percent of null values that will be filled: {:.2f}'.format(100 * raw['Tag'].isnull().sum() / raw.shape[0]) + '%')\n",
    "\n",
    "\n",
    "            # Fill NaN values with the previous value.\n",
    "            if self.method == 'ffill':\n",
    "                raw=raw.fillna(method='ffill',axis=0)  # interpolate with previos values\n",
    "                raw=raw.fillna(method='bfill',axis=0)  # when the first value is null, this is not filled, so it is necessary fill it with the next value\n",
    "\n",
    "            # Fill NaN values interpolated it\n",
    "            if self.method == 'interpolate':\n",
    "                raw = raw.interpolate()  # interpolate values\n",
    "                raw=raw.fillna(method='ffill',axis=0)  # fill Tag\n",
    "\n",
    "            #pinfo: opcional para mas detalles: revisar el largo de la data de cada uno de los tags\n",
    "            print('revisar el largo de la data: ', raw.shape)\n",
    "\n",
    "            # concat\n",
    "            df=pd.concat([df, raw])\n",
    "            \n",
    "        print('\\nNUEVO - Tamaño data raw: ', df.shape)\n",
    "        print('NUEVO - Num Real Obs.: ', df['datetime'].unique().shape[0])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20ff787-1a9c-4348-ba82-ac0f21a8be44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date:  2021-01-01\n",
      "end_date:  2023-01-01\n"
     ]
    }
   ],
   "source": [
    "# obtener fechas de inicio y termino definido para el entrenamiento\n",
    "json_params = 'config/params.json'\n",
    "with open(json_params, 'r') as file:\n",
    "    params = json.load(file)\n",
    "\n",
    "# get start and end date train\n",
    "start_date = params['blanqueo_santafe_all']['data_train']['start_date_train']\n",
    "end_date = params['blanqueo_santafe_all']['data_train']['end_date_train']\n",
    "\n",
    "print('start_date: ',start_date)\n",
    "print('end_date: ', end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a945c90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "applying ImputerNaNs...\n",
      "\n",
      "Processing tag:  230AIT446.PNT\n",
      "Amount of null values that will be filled:  5369\n",
      "Percent of null values that will be filled: 2.55%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIC022.MEAS\n",
      "Amount of null values that will be filled:  4943\n",
      "Percent of null values that will be filled: 2.35%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIC126.MEAS\n",
      "Amount of null values that will be filled:  6763\n",
      "Percent of null values that will be filled: 3.21%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIC224.MEAS\n",
      "Amount of null values that will be filled:  5176\n",
      "Percent of null values that will be filled: 2.46%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIC286.MEAS\n",
      "Amount of null values that will be filled:  3944\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIC324.MEAS\n",
      "Amount of null values that will be filled:  3942\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIC433.MEAS\n",
      "Amount of null values that will be filled:  4867\n",
      "Percent of null values that will be filled: 2.31%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIT063A.PNT\n",
      "Amount of null values that will be filled:  3954\n",
      "Percent of null values that will be filled: 1.88%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIT063B.PNT\n",
      "Amount of null values that will be filled:  3950\n",
      "Percent of null values that will be filled: 1.88%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIT225A.PNT\n",
      "Amount of null values that will be filled:  3949\n",
      "Percent of null values that will be filled: 1.88%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIT225B.PNT\n",
      "Amount of null values that will be filled:  3952\n",
      "Percent of null values that will be filled: 1.88%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIT322A.PNT\n",
      "Amount of null values that will be filled:  5325\n",
      "Percent of null values that will be filled: 2.53%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIT322B.PNT\n",
      "Amount of null values that will be filled:  3945\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240AIT416B.PNT\n",
      "Amount of null values that will be filled:  3942\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FI020A.PNT\n",
      "Amount of null values that will be filled:  3935\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FI020A_HRS_D1.C\n",
      "Amount of null values that will be filled:  4716\n",
      "Percent of null values that will be filled: 2.24%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FI020A_HRS_DO.C\n",
      "Amount of null values that will be filled:  4716\n",
      "Percent of null values that will be filled: 2.24%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FI020A_HRS_EOP.C\n",
      "Amount of null values that will be filled:  4716\n",
      "Percent of null values that will be filled: 2.24%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FI020A_HRS_P.C\n",
      "Amount of null values that will be filled:  4715\n",
      "Percent of null values that will be filled: 2.24%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FI020A_HRS_TORRE.C\n",
      "Amount of null values that will be filled:  4715\n",
      "Percent of null values that will be filled: 2.24%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FI020B.PNT\n",
      "Amount of null values that will be filled:  3944\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FI108A.PNT\n",
      "Amount of null values that will be filled:  3899\n",
      "Percent of null values that will be filled: 1.85%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC024.MEAS\n",
      "Amount of null values that will be filled:  4914\n",
      "Percent of null values that will be filled: 2.33%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC107.MEAS\n",
      "Amount of null values that will be filled:  4089\n",
      "Percent of null values that will be filled: 1.94%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC110.MEAS\n",
      "Amount of null values that will be filled:  4868\n",
      "Percent of null values that will be filled: 2.31%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC116.MEAS\n",
      "Amount of null values that will be filled:  4912\n",
      "Percent of null values that will be filled: 2.33%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC118.MEAS\n",
      "Amount of null values that will be filled:  4912\n",
      "Percent of null values that will be filled: 2.33%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC210.MEAS\n",
      "Amount of null values that will be filled:  4912\n",
      "Percent of null values that will be filled: 2.33%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC212.MEAS\n",
      "Amount of null values that will be filled:  12809\n",
      "Percent of null values that will be filled: 6.08%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC236.MEAS\n",
      "Amount of null values that will be filled:  4887\n",
      "Percent of null values that will be filled: 2.32%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC310.MEAS\n",
      "Amount of null values that will be filled:  3945\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC312.MEAS\n",
      "Amount of null values that will be filled:  3945\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC397.MEAS\n",
      "Amount of null values that will be filled:  4857\n",
      "Percent of null values that will be filled: 2.31%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FIC440.MEAS\n",
      "Amount of null values that will be filled:  5200\n",
      "Percent of null values that will be filled: 2.47%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY024A.RO01\n",
      "Amount of null values that will be filled:  3901\n",
      "Percent of null values that will be filled: 1.85%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY039.RO01\n",
      "Amount of null values that will be filled:  5259\n",
      "Percent of null values that will be filled: 2.50%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY050.RO02\n",
      "Amount of null values that will be filled:  3877\n",
      "Percent of null values that will be filled: 1.84%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY107A.RO01\n",
      "Amount of null values that will be filled:  3874\n",
      "Percent of null values that will be filled: 1.84%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY118B.RO01\n",
      "Amount of null values that will be filled:  3939\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY11PB.RO01\n",
      "Amount of null values that will be filled:  3939\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY210A.RO01\n",
      "Amount of null values that will be filled:  3941\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY212.RO01\n",
      "Amount of null values that will be filled:  5325\n",
      "Percent of null values that will be filled: 2.53%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY218.RO02\n",
      "Amount of null values that will be filled:  3941\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY312.RO01\n",
      "Amount of null values that will be filled:  3944\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY318.RO02\n",
      "Amount of null values that will be filled:  4562\n",
      "Percent of null values that will be filled: 2.17%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY397.RO01\n",
      "Amount of null values that will be filled:  5236\n",
      "Percent of null values that will be filled: 2.49%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240FY430.RO01\n",
      "Amount of null values that will be filled:  4548\n",
      "Percent of null values that will be filled: 2.16%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240LIT010.PNT\n",
      "Amount of null values that will be filled:  4912\n",
      "Percent of null values that will be filled: 2.33%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240TI139.PNT\n",
      "Amount of null values that will be filled:  3941\n",
      "Percent of null values that will be filled: 1.87%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240TIC023.MEAS\n",
      "Amount of null values that will be filled:  4913\n",
      "Percent of null values that will be filled: 2.33%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240TIT223.PNT\n",
      "Amount of null values that will be filled:  5236\n",
      "Percent of null values that will be filled: 2.49%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  240TIT323.PNT\n",
      "Amount of null values that will be filled:  3981\n",
      "Percent of null values that will be filled: 1.89%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  276CLO2_LGA.RO02\n",
      "Amount of null values that will be filled:  3558\n",
      "Percent of null values that will be filled: 1.69%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  S220ALDP010\n",
      "Amount of null values that will be filled:  10371\n",
      "Percent of null values that will be filled: 4.93%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  S240ALDP022\n",
      "Amount of null values that will be filled:  5489\n",
      "Percent of null values that will be filled: 2.61%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  S240ALDP031\n",
      "Amount of null values that will be filled:  5631\n",
      "Percent of null values that will be filled: 2.67%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  S240ALDP032\n",
      "Amount of null values that will be filled:  7110\n",
      "Percent of null values that will be filled: 3.38%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  S276PER002\n",
      "Amount of null values that will be filled:  10124\n",
      "Percent of null values that will be filled: 4.81%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  S2MAQUINAT07\n",
      "Amount of null values that will be filled:  3428\n",
      "Percent of null values that will be filled: 1.63%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  S76ALE017\n",
      "Amount of null values that will be filled:  6598\n",
      "Percent of null values that will be filled: 3.13%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "Processing tag:  SSTRIPPING015\n",
      "Amount of null values that will be filled:  3385\n",
      "Percent of null values that will be filled: 1.61%\n",
      "revisar el largo de la data:  (210529, 3)\n",
      "\n",
      "NUEVO - Tamaño data raw:  (12842269, 3)\n",
      "NUEVO - Num Real Obs.:  210529\n"
     ]
    }
   ],
   "source": [
    "# crear instancia de la clase\n",
    "imputer = ImputerNaNs(method = 'ffill', \n",
    "                      start_date = start_date, \n",
    "                      end_date = end_date\n",
    "                     )\n",
    "\n",
    "# transform\n",
    "basic_preprocessed_data = imputer.transform(basic_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "683ae038-2f81-4233-bc51-042bd4af8201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Tag</th>\n",
       "      <th>PV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>230AIT446.PNT</td>\n",
       "      <td>11.55654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:05:00</td>\n",
       "      <td>230AIT446.PNT</td>\n",
       "      <td>11.55354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 00:10:00</td>\n",
       "      <td>230AIT446.PNT</td>\n",
       "      <td>11.55110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 00:15:00</td>\n",
       "      <td>230AIT446.PNT</td>\n",
       "      <td>11.54881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 00:20:00</td>\n",
       "      <td>230AIT446.PNT</td>\n",
       "      <td>11.54548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210524</th>\n",
       "      <td>2023-01-01 23:40:00</td>\n",
       "      <td>SSTRIPPING015</td>\n",
       "      <td>534.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210525</th>\n",
       "      <td>2023-01-01 23:45:00</td>\n",
       "      <td>SSTRIPPING015</td>\n",
       "      <td>534.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526</th>\n",
       "      <td>2023-01-01 23:50:00</td>\n",
       "      <td>SSTRIPPING015</td>\n",
       "      <td>534.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210527</th>\n",
       "      <td>2023-01-01 23:55:00</td>\n",
       "      <td>SSTRIPPING015</td>\n",
       "      <td>534.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210528</th>\n",
       "      <td>2023-01-02 00:00:00</td>\n",
       "      <td>SSTRIPPING015</td>\n",
       "      <td>534.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12842269 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime            Tag         PV\n",
       "0      2021-01-01 00:00:00  230AIT446.PNT   11.55654\n",
       "1      2021-01-01 00:05:00  230AIT446.PNT   11.55354\n",
       "2      2021-01-01 00:10:00  230AIT446.PNT   11.55110\n",
       "3      2021-01-01 00:15:00  230AIT446.PNT   11.54881\n",
       "4      2021-01-01 00:20:00  230AIT446.PNT   11.54548\n",
       "...                    ...            ...        ...\n",
       "210524 2023-01-01 23:40:00  SSTRIPPING015  534.00000\n",
       "210525 2023-01-01 23:45:00  SSTRIPPING015  534.00000\n",
       "210526 2023-01-01 23:50:00  SSTRIPPING015  534.00000\n",
       "210527 2023-01-01 23:55:00  SSTRIPPING015  534.00000\n",
       "210528 2023-01-02 00:00:00  SSTRIPPING015  534.00000\n",
       "\n",
       "[12842269 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baab086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8969acff",
   "metadata": {},
   "source": [
    "### 5. Save data raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f46fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data pkl cloud\n",
    "path_raw_data = 'artifacts/data/data_raw_preprocessed.pkl'\n",
    "with open(path_raw_data, \"wb\") as output:\n",
    "    pickle.dump(basic_preprocessed_data, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f829a1-761f-4932-a8e2-c38bc1483bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1062bd-7abb-408c-975e-ff4d23c26f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dd640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
